---
title: "E. None of the Above"
description: "An interactive blog post with multiple choice questions that explores how we can better prepare students for real-world decision making."
date: "2025-07-13"
author: "Matthew Young"
readTime: "5 min read"
type: "multiple-choice"
featured: true
tags: ["education", "interactive", "critical-thinking"]
---

# Interactive Setup

This post demonstrates how real-world decisions differ from multiple choice questions.

## Question
Your fast-growing startup just raised Series A funding. What should you do about hiring and remote work? Select the correct answer:

## Options
A. Hire globally and go fully remote to access the best talent worldwide at competitive rates
B. Keep everyone local and in-office to maintain culture, collaboration, and rapid iteration
C. Build hybrid 'hubs' in 3-4 major cities to balance talent access with in-person connection
D. Stay local for core team but hire remote specialists for specific skills you can't find nearby

## Follow-up
- **Question**: "So which is the correct answer?"
- **Subheading**: "Is there a correct answer?"

---

# Real Questions Aren't Multiple Choice

To prepare kids for the real world, we simplify it. We teach them hard skills that we hope will help them tackle real problems. While hard skills are measurable and important, I believe we've gone too far. We favor teaching hard skills because they're easy to evaluate, but as the world changes, this approach becomes increasingly problematic. 

Testing students with questions that have correct answers helps build foundational skills and makes teaching at scale possible. To meet growing demands, we've embraced multiple choice questions. I understand the reasoningâ€”multiple choice is efficient, scalable, fair, and allows us to teach thousands of students with limited resources.

But we've created a trap. We simplify to evaluate at scale, then we can only teach what fits those evaluations. The measurement tool shapes what we measure, and what we measure shapes what we teach.

To break it down, we face two key issues:

1. When evaluating hard skills, we rely on multiple choice questions that reward finding the right answer rather than developing reasoning and critical thinking.
2. We focus solely on hard skills because they fit our current methods of large-scale evaluation.

A student who guesses correctly looks the same as one who reasons brilliantly. Yet with answers now easily accessible to students, the ability to reason well might be more important than the right answer. 

Teachers recognize this problem. They want to understand how students think. But one teacher can only deeply evaluate a limited number of students. The system pushes them back to standardized tests.

Here's what's changing: the constraint has always been human attention. One expert could only guide a handful of students. That's why personalized tutoring worked but couldn't scale.

What if that constraint is dissolving?

With AI, teachers could make all math questions open-ended, with students showing their work. AI could help provide partial credit and personalized assistance based on specific mistakes. This technology can help break the multiple choice trap.

Once our evaluation becomes more flexible, we can also explore questions that target more than one skill. Imagine a teacher assigning the remote work dilemma. Students write their analysis, and AI helps the teacher see each student's reasoning: who considered trade-offs, who wrestled with uncertainty, who reached for false certainty. Thirty students could each receive the attention that used to be possible for only three.

AI can help us improve how we teach today and move beyond our current system's limitations.